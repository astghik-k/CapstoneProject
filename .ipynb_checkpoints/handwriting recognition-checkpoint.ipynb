{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324d9043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting packaging>=21.3 (from pytesseract)\n",
      "  Using cached packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting Pillow>=8.0.0 (from pytesseract)\n",
      "  Using cached pillow-10.3.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (9.2 kB)\n",
      "Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
      "Using cached pillow-10.3.0-cp310-cp310-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Installing collected packages: Pillow, packaging, pytesseract\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.4.1 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.1 requires pyqtwebengine<5.16, which is not installed.\n",
      "pytorchyolo 1.8.0 requires Pillow<10.0.0,>=9.1.0, but you have pillow 10.3.0 which is incompatible.\n",
      "chainlit 1.0.200 requires packaging<24.0,>=23.1, but you have packaging 24.0 which is incompatible.\n",
      "coremltools 6.3.0 requires protobuf<=4.0.0,>=3.1.0, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-10.3.0 packaging-24.0 pytesseract-0.3.10\n",
      "\u001b[33mWARNING: Target directory /Users/astghik.kostanyan/Desktop/capstone/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /Users/astghik.kostanyan/Desktop/capstone/packaging-24.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /Users/astghik.kostanyan/Desktop/capstone/pillow-10.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /Users/astghik.kostanyan/Desktop/capstone/pytesseract already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /Users/astghik.kostanyan/Desktop/capstone/pytesseract-0.3.10.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /Users/astghik.kostanyan/Desktop/capstone/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract --target=/Users/astghik.kostanyan/Desktop/capstone\n",
    "pip install google-cloud-vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a88af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "import openpyxl  # Required by pandas for Excel writing\n",
    "\n",
    "def authenticate_with_service_account(key_path):\n",
    "    credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "    return client\n",
    "\n",
    "def detect_handwritten_text(image_path, client, visually_similar_groups):\n",
    "    with io.open(image_path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "    image_context = vision.ImageContext(language_hints=['en', 'el']) \n",
    "    response = client.document_text_detection(image=image, image_context=image_context)\n",
    "    document = response.full_text_annotation\n",
    "\n",
    "    full_text = document.text  # Simplified extraction of full text\n",
    "    detailed_confidences = []\n",
    "\n",
    "    character_confidences = {}\n",
    "\n",
    "    for page in document.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    for symbol in word.symbols:\n",
    "                        char = symbol.text\n",
    "                        confidence = symbol.confidence\n",
    "\n",
    "                        character_confidences[char] = confidence  # Store each character's confidence\n",
    "\n",
    "                        similar_chars_confidences = {}\n",
    "                        if confidence < 0.7:\n",
    "                            for group, similar_chars in visually_similar_groups.items():\n",
    "                                if char in similar_chars:\n",
    "                                    for similar_char in similar_chars:\n",
    "                                        if similar_char != char:\n",
    "                                            # Only add if confidence exists and is not None\n",
    "                                            if similar_char in character_confidences and character_confidences[similar_char] is not None:\n",
    "                                                similar_chars_confidences[similar_char] = character_confidences[similar_char]\n",
    "\n",
    "                        detailed_confidences.append({\n",
    "                            'image_name': os.path.basename(image_path),\n",
    "                            'character': char,\n",
    "                            'confidence': confidence,\n",
    "                            'similar_chars': similar_chars_confidences if similar_chars_confidences else None\n",
    "                        })\n",
    "\n",
    "    return full_text, detailed_confidences\n",
    "\n",
    "\n",
    "def process_folder(folder_path, key_path, output_text_file, output_excel_file):\n",
    "    client = authenticate_with_service_account(key_path)\n",
    "    visually_similar_groups = {\n",
    "    'Group 1': {'(', 'c'},\n",
    "    'Group 2': {'c', '<'},\n",
    "    'Group 3': {'c', 'e'},\n",
    "    'Group 4': {'e', 'l'},\n",
    "    'Group 5': {'e', 'o'},\n",
    "    'Group 6': {'o', '0'},\n",
    "    'Group 7': {'=', 'z'},\n",
    "    'Group 8': {'z', 'r'},\n",
    "    'Group 9': {'r', '2'},\n",
    "    'Group 10': {'z', '2'},\n",
    "    'Group 11': {'v', 'r'},\n",
    "    'Group 12': {'r', 'n'},\n",
    "    'Group 13': {'t', '+'},\n",
    "    'Group 14': {'y', 'g'},\n",
    "    'Group 15': {'2', 'alpha'},\n",
    "    'Group 16': {'j', 'i'},\n",
    "    'Group 17': {'i', ';'},\n",
    "    'Group 18': {'j', ';'},\n",
    "    'Group 19': {'{', '('},\n",
    "    'Group 20': {'O', 'D'}}\n",
    "    all_confidences = []\n",
    "\n",
    "    with open(output_text_file, 'w') as text_file:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                full_text, image_confidences = detect_handwritten_text(image_path, client, visually_similar_groups)\n",
    "                text_file.write(f\"{filename}: {full_text}\\n\")\n",
    "                all_confidences.extend(image_confidences)\n",
    "\n",
    "    df = pd.DataFrame(all_confidences)\n",
    "    df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'processed'  # Path to your processed images directory\n",
    "key_path = 'capstone-420319-c5b354e85ad0.json'\n",
    "output_text_file = 'full_texts.txt'  # Output text file for full texts\n",
    "output_excel_file = 'character_confidences.xlsx'  # Output Excel file for character confidences\n",
    "\n",
    "process_folder(folder_path, key_path, output_text_file, output_excel_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca78da3",
   "metadata": {},
   "source": [
    "## pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca47f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytesseract\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "\n",
    "# # Path to your image file within the Capstone folder\n",
    "# image_path = '/Users/astghik.kostanyan/Desktop/Capstone/unnamed2_page_3_cropped.jpg'\n",
    "\n",
    "# # Load the image\n",
    "# image = Image.open(image_path)\n",
    "\n",
    "# # Perform OCR\n",
    "# text = pytesseract.image_to_string(image, lang='eng')\n",
    "\n",
    "# # Get confidence scores\n",
    "# confidences = []\n",
    "# boxes = pytesseract.image_to_boxes(image)\n",
    "# for b in boxes.splitlines():\n",
    "#     b = b.split(' ')\n",
    "#     character = b[0]\n",
    "#     confidence = float(b[-1])\n",
    "#     confidences.append((character, confidence))\n",
    "\n",
    "# # Print extracted text\n",
    "# print(\"Extracted Text:\", text)\n",
    "\n",
    "# # Print confidence scores for each character\n",
    "# print(\"Confidence Scores:\")\n",
    "# for character, confidence in confidences:\n",
    "#     print(f\"Character: {character}, Confidence: {confidence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400fc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7dbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d0c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acb7301e",
   "metadata": {},
   "source": [
    "## EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb95165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import easyocr\n",
    "\n",
    "# reader = easyocr.Reader(['en'])\n",
    "# result = reader.readtext(image_path)\n",
    "\n",
    "# # Print each character along with its confidence score\n",
    "# print(\"Character    Confidence Score\")\n",
    "# for text_result in result:\n",
    "#     text = text_result[1]\n",
    "#     confidence = text_result[2]\n",
    "#     for character in text:\n",
    "#         print(f\"{character:<12} {confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82878b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3a3c87",
   "metadata": {},
   "source": [
    "## Google Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97acc13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "# from google.cloud import vision\n",
    "# from google.cloud.vision_v1 import types\n",
    "\n",
    "\n",
    "\n",
    "# # Authenticate with your API key\n",
    "# client = vision.ImageAnnotatorClient.from_service_account_json('capstone-420319-c5b354e85ad0.json')\n",
    "\n",
    "# # Read the image file\n",
    "# with io.open(image_path, 'rb') as image_file:\n",
    "#     content = image_file.read()\n",
    "\n",
    "# # Create an image object\n",
    "# image = vision.Image(content=content)\n",
    "\n",
    "# # Perform handwritten text detection\n",
    "# response = client.text_detection(image=image)\n",
    "\n",
    "# # Extract text and confidence scores\n",
    "# texts = response.text_annotations\n",
    "# extracted_text = texts[0].description\n",
    "\n",
    "# # Print the extracted text and confidence scores\n",
    "# print(extracted_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c613a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "# import json\n",
    "# from google.cloud import vision\n",
    "# # from google.cloud.vision_v1 import enums\n",
    "# from google.oauth2 import service_account\n",
    "\n",
    "# def authenticate_with_service_account(key_path):\n",
    "#     credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "#     client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "#     return client\n",
    "\n",
    "# def detect_handwritten_text(image_path, client, language_hint=None):\n",
    "#     with io.open(image_path, 'rb') as image_file:\n",
    "#         content = image_file.read()\n",
    "\n",
    "#     image = vision.Image(content=content)\n",
    "#     image_context = vision.ImageContext(language_hints=[language_hint]) if language_hint else None\n",
    "#     response = client.document_text_detection(image=image, image_context=image_context)\n",
    "#     document = response.full_text_annotation\n",
    "\n",
    "#     text = ''\n",
    "#     confidences = []\n",
    "\n",
    "#     for page in document.pages:\n",
    "#         for block in page.blocks:\n",
    "#             for paragraph in block.paragraphs:\n",
    "#                 for word in paragraph.words:\n",
    "#                     for symbol in word.symbols:\n",
    "#                         text += symbol.text\n",
    "#                         confidences.append(symbol.confidence)\n",
    "\n",
    "#     return text, confidences\n",
    "\n",
    "# # Path to your JSON key file\n",
    "# key_path = 'capstone-420319-c5b354e85ad0.json'\n",
    "\n",
    "# # Authenticate with service account\n",
    "# client = authenticate_with_service_account(key_path)\n",
    "\n",
    "# # Language hint (e.g., 'en' for English, 'fr' for French)\n",
    "# language_hint = 'english'\n",
    "\n",
    "# # Detect handwritten text and get confidences\n",
    "# text, confidences = detect_handwritten_text(image_path, client, language_hint)\n",
    "\n",
    "# # Print confidence scores for each character\n",
    "# print_confidence_scores(text, confidences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9d44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4945e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb2931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6caf6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58bab6b6",
   "metadata": {},
   "source": [
    "## For all similar letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52b5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "# from google.cloud import vision\n",
    "# from google.oauth2 import service_account\n",
    "\n",
    "# def authenticate_with_service_account(key_path):\n",
    "#     credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "#     client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "#     return client\n",
    "\n",
    "# def detect_handwritten_text(image_path, client, visually_similar_groups, language_hint=None):\n",
    "#     with io.open(image_path, 'rb') as image_file:\n",
    "#         content = image_file.read()\n",
    "\n",
    "#     image = vision.Image(content=content)\n",
    "#     image_context = vision.ImageContext(language_hints=['en', 'el'])  # Include Greek in language hints\n",
    "#     response = client.document_text_detection(image=image, image_context=image_context)\n",
    "\n",
    "#     # Simplified method to extract full text\n",
    "#     full_text = response.full_text_annotation.text\n",
    "\n",
    "#     detailed_confidences = {}\n",
    "#     # Process each page, block, paragraph, word, and symbol to extract confidence and similar characters\n",
    "#     for page in response.full_text_annotation.pages:\n",
    "#         for block in page.blocks:\n",
    "#             for paragraph in block.paragraphs:\n",
    "#                 for word in paragraph.words:\n",
    "#                     for symbol in word.symbols:\n",
    "#                         char = symbol.text\n",
    "#                         confidence = symbol.confidence\n",
    "\n",
    "#                         if char not in detailed_confidences:\n",
    "#                             detailed_confidences[char] = {\n",
    "#                                 'confidence': confidence,\n",
    "#                                 'similar_chars_confidences': {}\n",
    "#                             }\n",
    "\n",
    "#                         # Populate similar characters' confidences for comparison\n",
    "#                         for group, similar_chars in visually_similar_groups.items():\n",
    "#                             if char in similar_chars:\n",
    "#                                 for similar_char in similar_chars:\n",
    "#                                     if similar_char != char:\n",
    "#                                         if similar_char in detailed_confidences:\n",
    "#                                             detailed_confidences[char]['similar_chars_confidences'][similar_char] = detailed_confidences[similar_char]['confidence']\n",
    "#                                         else:\n",
    "#                                             detailed_confidences[char]['similar_chars_confidences'][similar_char] = None\n",
    "\n",
    "#                         # Print each character, confidence, and similar characters' confidences immediately\n",
    "#                         print(f\"Character: {char}, Confidence: {confidence}\")\n",
    "#                         if detailed_confidences[char]['similar_chars_confidences']:\n",
    "#                             print(f\"  Similar Characters Confidences: {detailed_confidences[char]['similar_chars_confidences']}\")\n",
    "\n",
    "#     return full_text, detailed_confidences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Print the full text at the beginning\n",
    "# print(full_text)\n",
    "\n",
    "# # Detect handwritten text and get detailed confidences\n",
    "# full_text, detailed_confidences = detect_handwritten_text(image_path, client, visually_similar_groups, language_hint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e3abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "# from google.cloud import vision\n",
    "# from google.oauth2 import service_account\n",
    "\n",
    "# def authenticate_with_service_account(key_path):\n",
    "#     credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "#     client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "#     return client\n",
    "\n",
    "# def detect_handwritten_text(image_path, client, visually_similar_groups, language_hint=None):\n",
    "#     with io.open(image_path, 'rb') as image_file:\n",
    "#         content = image_file.read()\n",
    "\n",
    "#     image = vision.Image(content=content)\n",
    "#     image_context = vision.ImageContext(language_hints=[language_hint] if language_hint else ['en'])  # Default language hint\n",
    "#     response = client.document_text_detection(image=image, image_context=image_context)\n",
    "\n",
    "#     full_text = response.full_text_annotation.text\n",
    "#     detailed_confidences = {}\n",
    "#     replacement_map = {}\n",
    "\n",
    "#     # Process each page, block, paragraph, word, and symbol\n",
    "#     for page in response.full_text_annotation.pages:\n",
    "#         for block in page.blocks:\n",
    "#             for paragraph in block.paragraphs:\n",
    "#                 for word in paragraph.words:\n",
    "#                     for symbol in word.symbols:\n",
    "#                         char = symbol.text\n",
    "#                         confidence = symbol.confidence\n",
    "#                         detailed_confidences[char] = confidence\n",
    "\n",
    "#                         # Check and compare similar character confidences\n",
    "#                         for group, similar_chars in visually_similar_groups.items():\n",
    "#                             if char in similar_chars:\n",
    "#                                 max_confidence = confidence\n",
    "#                                 best_char = char\n",
    "#                                 for similar_char in similar_chars:\n",
    "#                                     if similar_char in detailed_confidences and detailed_confidences[similar_char] is not None:\n",
    "#                                         if detailed_confidences[similar_char] > max_confidence:\n",
    "#                                             max_confidence = detailed_confidences[similar_char]\n",
    "#                                             best_char = similar_char\n",
    "#                                 replacement_map[char] = best_char\n",
    "\n",
    "#     # Replace characters in the full text based on the highest confidence characters\n",
    "#     corrected_text = ''.join([replacement_map.get(char, char) for char in full_text])\n",
    "\n",
    "#     return corrected_text, detailed_confidences\n",
    "\n",
    "\n",
    "# # Detect handwritten text and get the corrected full text\n",
    "# corrected_text, detailed_confidences = detect_handwritten_text(image_path, client, visually_similar_groups, language_hint)\n",
    "\n",
    "# # Print the corrected full text\n",
    "# print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd724bd3",
   "metadata": {},
   "source": [
    "## with 0.5 conf thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5958773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import io\n",
    "# from google.cloud import vision\n",
    "# from google.oauth2 import service_account\n",
    "\n",
    "# def authenticate_with_service_account(key_path):\n",
    "#     credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "#     client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "#     return client\n",
    "\n",
    "# def detect_handwritten_text(image_path, client, visually_similar_groups, language_hint=None):\n",
    "#     with io.open(image_path, 'rb') as image_file:\n",
    "#         content = image_file.read()\n",
    "\n",
    "#     image = vision.Image(content=content)\n",
    "#     image_context = vision.ImageContext(language_hints=[language_hint]) if language_hint else None\n",
    "#     response = client.document_text_detection(image=image, image_context=image_context)\n",
    "#     document = response.full_text_annotation\n",
    "\n",
    "#     full_text = document.text  # Simplified extraction of full text\n",
    "#     detailed_confidences = {}\n",
    "\n",
    "#     for page in document.pages:\n",
    "#         for block in page.blocks:\n",
    "#             for paragraph in block.paragraphs:\n",
    "#                 for word in paragraph.words:\n",
    "#                     for symbol in word.symbols:\n",
    "#                         char = symbol.text\n",
    "#                         confidence = symbol.confidence\n",
    "\n",
    "#                         if char not in detailed_confidences:\n",
    "#                             detailed_confidences[char] = {\n",
    "#                                 'confidence': confidence,\n",
    "#                                 'similar_chars_confidences': {}\n",
    "#                             }\n",
    "\n",
    "#                         # Always print the character and its confidence\n",
    "#                         print(f\"Character: {char}, Confidence: {confidence}\")\n",
    "\n",
    "#                         # Only check similar characters if confidence is below 0.7\n",
    "#                         if confidence < 0.7:\n",
    "#                             for group, similar_chars in visually_similar_groups.items():\n",
    "#                                 if char in similar_chars:\n",
    "#                                     for similar_char in similar_chars:\n",
    "#                                         if similar_char != char:\n",
    "#                                             # Check if similar character has been encountered and recorded before\n",
    "#                                             if similar_char in detailed_confidences and detailed_confidences[similar_char]['confidence'] is not None:\n",
    "#                                                 detailed_confidences[char]['similar_chars_confidences'][similar_char] = detailed_confidences[similar_char]['confidence']\n",
    "\n",
    "#                             # Print similar characters' confidences if any\n",
    "#                             if detailed_confidences[char]['similar_chars_confidences']:\n",
    "#                                 # Filter out None values before printing\n",
    "#                                 filtered_confidences = {k: v for k, v in detailed_confidences[char]['similar_chars_confidences'].items() if v is not None}\n",
    "#                                 if filtered_confidences:\n",
    "#                                     print(f\"  Similar Characters Confidences: {filtered_confidences}\")\n",
    "\n",
    "#     return full_text, detailed_confidences\n",
    "\n",
    "# # Example of initializing and using the function\n",
    "\n",
    "# client = authenticate_with_service_account(key_path)\n",
    "\n",
    "\n",
    "# # Detect handwritten text and get detailed confidences\n",
    "# full_text, detailed_confidences = detect_handwritten_text(image_path, client, visually_similar_groups, language_hint)\n",
    "\n",
    "# # Print the full text at the beginning\n",
    "# print(\"Full Text:\", full_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05232c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b15e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce840a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8903754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3867bea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0eca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa207e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ac777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbf346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f52502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a9cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bc54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8240bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Generate word cloud from characters\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df['Character']))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Handwritten Characters')\n",
    "plt.show()\n",
    "plt.savefig('character_wordcloud.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for character length\n",
    "df['Character Length'] = df['Character'].apply(len)\n",
    "\n",
    "# Plot scatter plot of confidence vs. character length\n",
    "plt.scatter(df['Character Length'], df['Confidence Score'], alpha=0.5, color='skyblue')\n",
    "plt.xlabel('Character Length')\n",
    "plt.ylabel('Confidence Score')\n",
    "plt.title('Confidence vs. Character Length')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07423aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_character_frequency_histogram(texts):\n",
    "    # Combine all detected text into a single string\n",
    "    all_text = ''.join(texts)\n",
    "    \n",
    "    # Count the frequency of each character\n",
    "    character_counts = {}\n",
    "    for char in all_text:\n",
    "        if char in character_counts:\n",
    "            character_counts[char] += 1\n",
    "        else:\n",
    "            character_counts[char] = 1\n",
    "    \n",
    "    # Plot the histogram\n",
    "    plt.figure(figsize=(18, 8))  # Increase the figure size\n",
    "    plt.bar(character_counts.keys(), character_counts.values())\n",
    "    plt.xlabel('Character')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Frequency Histogram of Characters')\n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "    plt.show()\n",
    "\n",
    "# Plot frequency histogram for each character\n",
    "plot_character_frequency_histogram(image_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fe223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_character_frequency_histogram(texts, threshold=500):\n",
    "    # Combine all detected text into a single string\n",
    "    all_text = ''.join(texts)\n",
    "    \n",
    "    # Count the frequency of each character\n",
    "    character_counts = {}\n",
    "    for char in all_text:\n",
    "        if char in character_counts:\n",
    "            character_counts[char] += 1\n",
    "        else:\n",
    "            character_counts[char] = 1\n",
    "    \n",
    "    # Filter characters with frequency > threshold\n",
    "    filtered_character_counts = {char: count for char, count in character_counts.items() if count > threshold}\n",
    "    \n",
    "    # Sort the character counts in descending order of frequency\n",
    "    sorted_character_counts = dict(sorted(filtered_character_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    # Plot the histogram\n",
    "    plt.figure(figsize=(18, 8))  # Increase the figure size\n",
    "    plt.bar(sorted_character_counts.keys(), sorted_character_counts.values())\n",
    "    plt.xlabel('Character')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Frequency Histogram of Characters (Frequency > 500)')\n",
    "    plt.xticks(rotation=0)  # Rotate x-axis labels for better readability\n",
    "    plt.show()\n",
    "    plt.savefig('frequency_histogram.jpg')\n",
    "\n",
    "\n",
    "# Plot frequency histogram for characters with frequency > 500\n",
    "plot_character_frequency_histogram(image_texts, threshold=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Read the contents of the text file\n",
    "with open('handwriting_results.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract detected text paragraphs\n",
    "detected_text = ''\n",
    "for line in lines:\n",
    "    if line.startswith('Detected Text:'):\n",
    "        detected_text += line.split(':', 1)[1].strip() + ' '\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(detected_text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save the word cloud as an image\n",
    "wordcloud.to_file('word_cloud.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8132c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
